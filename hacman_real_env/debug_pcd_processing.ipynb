{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Started camera 0\n",
      "Started camera 2\n",
      "Started camera 3\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from hacman_real_env.pcd_env import PCDObsEnv\n",
    "env = PCDObsEnv(camera_alignment=False) # set to False to start from scratch\n",
    "\n",
    "colors = [np.random.rand(3) for i in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Camera PCD Preprocessing\n",
    "\n",
    "Processing consists of the following steps:\n",
    "- random downsample to 1/4 of the points\n",
    "- voxel downsample\n",
    "- remove outliers\n",
    "- estimate normals\n",
    "- compute FPFH features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCD shape: 340717\n",
      ":: Random downsample to 1/5 size.\n",
      ":: Downsample with a voxel size 0.005.\n",
      ":: Remove radius outlier with radius 0.020.\n",
      "Showing outliers (red) and inliers (gray): \n",
      ":: Estimate normal with search radius 0.020.\n",
      ":: Compute FPFH feature with search radius 0.025.\n"
     ]
    }
   ],
   "source": [
    "def display_inlier_outlier(cloud, ind):\n",
    "    # Compute normals to help visualize\n",
    "    # cloud.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "    inlier_cloud = cloud.select_by_index(ind)\n",
    "    inlier_cloud.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "    outlier_cloud = cloud.select_by_index(ind, invert=True)\n",
    "\n",
    "    print(\"Showing outliers (red) and inliers (gray): \")\n",
    "    outlier_cloud.paint_uniform_color([1, 0, 0])\n",
    "    inlier_cloud.paint_uniform_color([0.8, 0.8, 0.8])\n",
    "    o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Random downsample to 1/5 size.\")\n",
    "    pcd_size = len(pcd.points)\n",
    "    pcd_down_mask = np.random.choice(pcd_size, int(pcd_size / 5))\n",
    "    pcd_down = pcd.select_by_index(pcd_down_mask)\n",
    "\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd_down.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius = 0.02\n",
    "    print(\":: Remove radius outlier with radius %.3f.\" % radius)\n",
    "    nb_points = int(((radius / voxel_size) ** 2) * 0.8) \n",
    "    cl, ind = pcd_down.remove_radius_outlier(nb_points=nb_points, radius=radius)\n",
    "    # cl, ind = pcd_down.remove_statistical_outlier(nb_neighbors=20,\n",
    "    #                                                 std_ratio=1)\n",
    "    display_inlier_outlier(pcd_down, ind)\n",
    "    pcd_down = cl\n",
    "\n",
    "    radius_normal = voxel_size * 4\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "voxel_size = 0.005\n",
    "# Obtain the point cloud\n",
    "pcd = env.get_single_raw_pcd(0)\n",
    "pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcd))\n",
    "print(f\"PCD shape: {len(pcd.points)}\")\n",
    "pcd_down, pcd_fpfh = preprocess_point_cloud(pcd, voxel_size)\n",
    "o3d.visualization.draw_geometries([pcd_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test if the pcd looks good after preprocessing\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "for cam_id in env.camera_indices:\n",
    "    processed_pcd = env.get_single_pcd(cam_id)\n",
    "    processed_pcd.paint_uniform_color(colors[cam_id])\n",
    "    pcd += processed_pcd\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning Multiple Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Aligning camera 0 with target pcd\n",
      ":: Apply point-to-point ICP\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 25187\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      ":: Aligning camera 2 with target pcd\n",
      ":: Apply point-to-point ICP\n",
      "RegistrationResult with fitness=5.510258e-01, inlier_rmse=4.091608e-03, and correspondence_set size of 16652\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99959372  0.02685219  0.00955831 -0.00686438]\n",
      " [-0.02671207  0.99953804 -0.01449731  0.04562095]\n",
      " [-0.00994318  0.0142361   0.99984922  0.01635733]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      ":: Aligning camera 3 with target pcd\n",
      ":: Apply point-to-point ICP\n",
      "RegistrationResult with fitness=8.176254e-01, inlier_rmse=4.230187e-03, and correspondence_set size of 17767\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 0.99936221 -0.03488579  0.00762536 -0.00841685]\n",
      " [ 0.03453765  0.99852839  0.0418116  -0.04880262]\n",
      " [-0.00907276 -0.04152157  0.99909641  0.02183709]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libusb: error [udev_hotplug_event] ignoring udev action change\n",
      "libusb: error [udev_hotplug_event] ignoring udev action bind\n"
     ]
    }
   ],
   "source": [
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def compute_align_to_target(target_pcd, other_pcds, threshold=0.01, visualize=False):\n",
    "    \"\"\"\n",
    "    Compute alignments from other_pcds to base_pcd\n",
    "    \n",
    "    Input:\n",
    "        target_pcd: Open3D point cloud\n",
    "        other_pcds: dict of Open3D point clouds {cam_id: pcd}\n",
    "    Return:\n",
    "        dict of transforms {cam_id: transforms}\n",
    "    \"\"\"\n",
    "    transforms = {}\n",
    "    for cam_id, source in other_pcds.items():        \n",
    "        print(f\":: Aligning camera {cam_id} with target pcd\")\n",
    "        print(\":: Apply point-to-point ICP\")\n",
    "        trans_init = np.identity(4)\n",
    "        # reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        #     source, target, threshold, trans_init,\n",
    "        #     o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "        reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "            source, target_pcd, threshold, trans_init,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "        print(reg_p2p)\n",
    "        print(\"Transformation is:\")\n",
    "        print(reg_p2p.transformation)\n",
    "        if visualize:\n",
    "            draw_registration_result(source, target_pcd, reg_p2p.transformation)\n",
    "\n",
    "        transforms[cam_id] = reg_p2p.transformation.copy()\n",
    "    \n",
    "    # For base camer, set to identity\n",
    "    transforms[base_cam_id] = np.identity(4)\n",
    "    \n",
    "    return transforms\n",
    "\n",
    "def align_pcds(pcds, transforms):\n",
    "    \"\"\"\n",
    "    Align point clouds using transforms\n",
    "    \n",
    "    Input:\n",
    "        pcds: dict of Open3D point clouds {cam_id: pcd}\n",
    "        transforms: dict of transforms {cam_id: transforms}.\n",
    "    Return:\n",
    "        Open3D point cloud\n",
    "    \"\"\"\n",
    "    transformed_pcds = o3d.geometry.PointCloud()\n",
    "    for cam_id in env.camera_indices:\n",
    "        transformed_pcd = pcds[cam_id].transform(transforms[cam_id])\n",
    "        transformed_pcd.paint_uniform_color(colors[cam_id])\n",
    "        transformed_pcds += transformed_pcd\n",
    "    \n",
    "    return transformed_pcds\n",
    "\n",
    "\n",
    "base_cam_id = 0     # Set all other cameras to align with camera 0\n",
    "\n",
    "# Obtain individual point clouds\n",
    "pcds = {}\n",
    "for cam_id in env.camera_indices:\n",
    "    pcds[cam_id] = env.get_single_pcd(cam_id)\n",
    "\n",
    "# Compute alignments\n",
    "transforms = compute_align_to_target(\n",
    "    pcds[base_cam_id], pcds, threshold=0.01, visualize=False) # Set to True to visualize pairwise alignment\n",
    "\n",
    "# Transform all point clouds\n",
    "camera_aligned_pcds = align_pcds(pcds, transforms)\n",
    "o3d.visualization.draw_geometries([camera_aligned_pcds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Save the results\"\"\"\n",
    "import os, json\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "save_dir = os.path.join(\"calibration\", \"finetune_results\")\n",
    "\n",
    "# Save the transform matrices as npz\n",
    "save_path = os.path.join(save_dir, \"camera_alignments.npz\")\n",
    "save_content = {\n",
    "    str(cam_id): transform for cam_id, transform in transforms.items()\n",
    "} # Convert cam_id to string to save as npz\n",
    "np.savez(save_path, **save_content)\n",
    "\n",
    "# Also save the humann readable transforms as xyz, quat into json\n",
    "save_content = {}\n",
    "for cam_id, transform in transforms.items():\n",
    "    quat = Rotation.from_matrix(transform[:3, :3]).as_quat()\n",
    "    save_content[cam_id] = {\n",
    "        \"xyz\": transform[:3, 3].tolist(),\n",
    "        \"quaternion\": quat.tolist()\n",
    "    }\n",
    "save_path = os.path.join(save_dir, \"camera_alignments.json\")\n",
    "with open(save_path, \"w\") as f:\n",
    "    json.dump(save_content, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning Base PCD to Ground Truth Plane (Not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Aligning camera combined with target pcd\n",
      ":: Apply point-to-point ICP\n",
      "RegistrationResult with fitness=7.767550e-01, inlier_rmse=3.228349e-03, and correspondence_set size of 60924\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 9.99995509e-01  9.12183142e-05 -2.99546888e-03  6.22445100e-05]\n",
      " [-6.25554319e-06  9.99598015e-01  2.83515316e-02 -1.45830893e-04]\n",
      " [ 2.99685093e-03 -2.83513855e-02  9.99593526e-01 -2.15817886e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "gt_plane = np.meshgrid(np.arange(0.1, 0.85, 0.005), np.arange(-0.85, 0.25, 0.005))\n",
    "gt_plane = np.vstack([gt_plane[0].flatten(), gt_plane[1].flatten(), np.zeros_like(gt_plane[0].flatten())]).T\n",
    "gt_plane_pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(gt_plane))\n",
    "gt_plane_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "# Obtain individual point clouds\n",
    "pcds = {}\n",
    "for cam_id in env.camera_indices:\n",
    "    pcds[cam_id] = env.get_single_pcd(cam_id)\n",
    "# Transform all point clouds (using previous alignment)\n",
    "camera_aligned_pcds = align_pcds(pcds, transforms)\n",
    "\n",
    "# Visualize point clouds\n",
    "obs_pcd = copy.deepcopy(camera_aligned_pcds)\n",
    "draw_registration_result(obs_pcd, gt_plane_pcd, np.identity(4))\n",
    "\n",
    "# Compute alignments\n",
    "pcds = {\"combined\": obs_pcd}\n",
    "gt_transforms = compute_align_to_target(\n",
    "    gt_plane_pcd, pcds, threshold=0.01, visualize=False) # Set to True to visualize pairwise alignment\n",
    "\n",
    "# We only need the z transform and the rotation\n",
    "base_transform = gt_transforms[\"combined\"]\n",
    "base_transform[0:2, 3] = 0\n",
    "\n",
    "# Apply base transform to all other transforms\n",
    "transformed_pcd = obs_pcd.transform(base_transform)\n",
    "draw_registration_result(obs_pcd, gt_plane_pcd, base_transform)\n",
    "# transformed_pcd = obs_pcd.transform(base_transform)\n",
    "# transformed_pcd.paint_uniform_color([1, 0, 0])\n",
    "# obs_pcd.paint_uniform_color([0, 0, 1])\n",
    "# o3d.visualization.draw_geometries([\n",
    "#     # transformed_pcd,\n",
    "#     obs_pcd,\n",
    "#     gt_plane_pcd\n",
    "#     ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacman-real",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
