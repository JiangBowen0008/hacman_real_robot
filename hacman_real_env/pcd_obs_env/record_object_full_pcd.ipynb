{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from pcd_obs_env import PCDObsEnv\n",
    "from segmentation import BackgroundGeometry\n",
    "from object_registration import preprocess_point_cloud, execute_global_registration, draw_registration_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_inlier_outlier(cloud, ind):\n",
    "    # Compute normals to help visualize\n",
    "    # cloud.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "\n",
    "    inlier_cloud = cloud.select_by_index(ind)\n",
    "    inlier_cloud.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "    outlier_cloud = cloud.select_by_index(ind, invert=True)\n",
    "\n",
    "    print(\"Showing outliers (red) and inliers (gray): \")\n",
    "    outlier_cloud.paint_uniform_color([1, 0, 0])\n",
    "    inlier_cloud.paint_uniform_color([0.8, 0.8, 0.8])\n",
    "    o3d.visualization.draw_geometries([inlier_cloud, outlier_cloud])\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded camera alignment for cameras [0, 1, 2, 3]\n",
      "Started camera 0\n",
      "Started camera 1\n",
      "Started camera 2\n",
      "Started camera 3\n",
      ":: Background point cloud loaded from /home/bowen/Projects/hacman_real_robot/hacman_real_env/pcd_obs_env/segmentation_params/background.pcd\n",
      ":: Background params loaded from /home/bowen/Projects/hacman_real_robot/hacman_real_env/pcd_obs_env/segmentation_params/background_params.pkl\n"
     ]
    }
   ],
   "source": [
    "obs_env = PCDObsEnv(\n",
    "    voxel_size=0.002\n",
    ")\n",
    "bg = BackgroundGeometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_name = 'color_block3'\n",
    "full_pcd = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_points(pcd1, pcd2, tansform1):\n",
    "    print(\"\")\n",
    "    print(\n",
    "        \"1) Please pick at least three correspondences using [shift + left click]\"\n",
    "    )\n",
    "    print(\"   Press [shift + right click] to undo point picking\")\n",
    "    print(\"2) After picking points, press 'Q' to close the window\")\n",
    "    pcd1 = copy.deepcopy(pcd1)\n",
    "    pcd2 = copy.deepcopy(pcd2)\n",
    "    pcd1.paint_uniform_color([1, 0.706, 0])\n",
    "    pcd2.paint_uniform_color([0, 0.651, 0.929])\n",
    "    pcd1.transform(tansform1)\n",
    "\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd1 + pcd2)\n",
    "    vis.run()  # user picks points\n",
    "    vis.destroy_window()\n",
    "    print(\"\")\n",
    "    picked_points = vis.get_picked_points()\n",
    "    num_points = len(picked_points)\n",
    "    assert num_points % 2 == 0, \"Must pick an even number of points\"\n",
    "\n",
    "    if num_points == 0:\n",
    "        return None\n",
    "    \n",
    "    picked_points1 = picked_points[:num_points // 2]\n",
    "    picked_points2 = np.array(picked_points[num_points // 2:]) - len(pcd1.points)\n",
    "    return picked_points1, picked_points2\n",
    "\n",
    "\n",
    "def demo_manual_registration(source, target, source_bg=None, target_bg=None):\n",
    "    print(\"Demo for manual ICP\")\n",
    "    print(\"Visualization of two point clouds before manual alignment\")\n",
    "    trans_init = np.identity(4)\n",
    "    picked_id_source = []\n",
    "    picked_id_target = []\n",
    "\n",
    "    while True:\n",
    "        # pick points from two point clouds and builds correspondences\n",
    "        picked_ids = pick_points(source, target, trans_init)\n",
    "        if picked_ids is None:\n",
    "            break\n",
    "\n",
    "        picked_id_source.extend(picked_ids[0])\n",
    "        picked_id_target.extend(picked_ids[1])\n",
    "        assert (len(picked_id_source) == len(picked_id_target))\n",
    "        corr = np.zeros((len(picked_id_source), 2))\n",
    "        corr[:, 0] = picked_id_source\n",
    "        corr[:, 1] = picked_id_target\n",
    "\n",
    "        # estimate rough transformation using correspondences\n",
    "        print(\"Compute a rough transform using the correspondences given by user\")\n",
    "        p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "        trans_init = p2p.compute_transformation(source, target,\n",
    "                                                o3d.utility.Vector2iVector(corr))\n",
    "\n",
    "        # point-to-point ICP for refinement\n",
    "        print(\"Perform point-to-point ICP refinement\")\n",
    "        threshold = 0.01  # 1cm distance threshold\n",
    "        reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, threshold, trans_init,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            criteria=o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-06, relative_rmse=1e-06, max_iteration=1000))\n",
    "        draw_registration_result(source, target, reg_p2p.transformation)\n",
    "        trans_init = reg_p2p.transformation\n",
    "        print(\"\")\n",
    "    \n",
    "    return trans_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cam 0. Capture takes 0.320s. Processing takes 0.042s.\n",
      "Cam 1. Capture takes 0.325s. Processing takes 0.031s.\n",
      "Cam 2. Capture takes 0.326s. Processing takes 0.036s.\n",
      "Cam 3. Capture takes 0.329s. Processing takes 0.029s.\n",
      "Obtaining pcds takes 1.446s.\n",
      "Demo for manual ICP\n",
      "Visualization of two point clouds before manual alignment\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] No point has been picked.\n",
      "[Open3D INFO] No point has been picked.\n",
      "[Open3D INFO] Picked point #395 (0.045, -0.095, 0.056) to add in queue.\n",
      "[Open3D INFO] No point has been picked.\n",
      "[Open3D INFO] Picked point #481 (-0.054, -0.1, 0.031) to add in queue.\n",
      "[Open3D INFO] Picked point #914 (-0.056, -0.17, 0.013) to add in queue.\n",
      "[Open3D INFO] Picked point #2105 (0.082, 0.094, 0.043) to add in queue.\n",
      "[Open3D INFO] Picked point #1845 (0.0087, 0.14, 0.077) to add in queue.\n",
      "[Open3D INFO] No point has been picked.\n",
      "[Open3D INFO] No point has been picked.\n",
      "[Open3D INFO] Picked point #1338 (-0.017, 0.19, 0.021) to add in queue.\n",
      "\n",
      "Compute a rough transform using the correspondences given by user\n",
      "Perform point-to-point ICP refinement\n",
      "\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Record an object pcd\n",
    "pcd = obs_env.get_pcd(\n",
    "    return_numpy=False,\n",
    "    color=True)\n",
    "pcd, bg_mask = bg.process_pcd(\n",
    "                    pcd,\n",
    "                    replace_bg=False,\n",
    "                    debug=False)\n",
    "obj_pcd = pcd.select_by_index(bg_mask, invert=True)\n",
    "bg_pcd = pcd.select_by_index(bg_mask, invert=False)\n",
    "\n",
    "# icp to the full pcd\n",
    "if full_pcd is None:\n",
    "    full_pcd = obj_pcd\n",
    "else:\n",
    "    transform = demo_manual_registration(\n",
    "        obj_pcd, full_pcd, None, None)\n",
    "    transformed_obj_pcd = obj_pcd.transform(transform)\n",
    "\n",
    "    full_pcd_ = copy.deepcopy(full_pcd)\n",
    "    full_pcd_ += transformed_obj_pcd\n",
    "    full_pcd_ = full_pcd_.voxel_down_sample(\n",
    "        voxel_size=0.002)\n",
    "    \n",
    "    o3d.visualization.draw_geometries([full_pcd_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing outliers (red) and inliers (gray): \n"
     ]
    }
   ],
   "source": [
    "# Remove outliers\n",
    "full_pcd_copy = copy.deepcopy(full_pcd_)\n",
    "_, idx = full_pcd_copy.remove_statistical_outlier(nb_neighbors=20, std_ratio=0.45)\n",
    "display_inlier_outlier(full_pcd_copy, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([full_pcd_copy.select_by_index(idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pcd = full_pcd_copy.select_by_index(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pcd_dir = 'full_pcds'\n",
    "os.makedirs(full_pcd_dir, exist_ok=True)\n",
    "filepath = os.path.join(full_pcd_dir, f\"{obj_name}.pcd\")\n",
    "o3d.io.write_point_cloud(filepath, full_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'orange_car'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libusb: error [udev_hotplug_event] ignoring udev action change\n",
      "libusb: error [udev_hotplug_event] ignoring udev action bind\n"
     ]
    }
   ],
   "source": [
    "obj_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_object_icp(source, target, output_fitness=False, visualize=False):\n",
    "    t_start = time.time()\n",
    "    # source = source.voxel_down_sample(0.005)\n",
    "    source.estimate_normals()\n",
    "    source.orient_normals_consistent_tangent_plane(10)\n",
    "    obb = source.get_oriented_bounding_box()\n",
    "    obb.color = (1, 0, 0)\n",
    "    \n",
    "    # target = target.voxel_down_sample(0.005)\n",
    "    target.estimate_normals()\n",
    "    target.orient_normals_consistent_tangent_plane(10)\n",
    "    obb_target = target.get_oriented_bounding_box()\n",
    "    obb_target.color = (0, 1, 0)\n",
    "    \n",
    "    # Global\n",
    "    voxel_size=0.005\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    icp_result = execute_global_registration(source_down, target_down,\n",
    "                                                source_fpfh, target_fpfh,\n",
    "                                                voxel_size)\n",
    "    t_global = time.time()\n",
    "\n",
    "    # source_new = copy.deepcopy(source).transform(icp_result)\n",
    "    # obb_new = source_new.get_oriented_bounding_box()\n",
    "    # obb_new.color = (0, 1, 0)\n",
    "    # o3d.visualization.draw_geometries([source, source_new, target, obb, obb_target, obb_new])\n",
    "\n",
    "    if visualize:\n",
    "        transform = np.eye(4)\n",
    "        draw_registration_result(source, target, transform)\n",
    "\n",
    "    # Local\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, max_correspondence_distance=0.2, init=icp_result,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "        criteria=o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-06, relative_rmse=1e-06, max_iteration=1000))\n",
    "    print(\"ICP: Fitness {:.2f} \\t MSE {:.2e}\".format(reg_p2p.fitness, reg_p2p.inlier_rmse))\n",
    "    icp_result = reg_p2p.transformation\n",
    "    t_local = time.time()\n",
    "    print(\"ICP: Global {:.2f} sec. \\t Local {:.2e} sec.\".format(t_global - t_start, t_local - t_global))\n",
    "\n",
    "    # # Finetuned local\n",
    "    # reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    #     source, target, max_correspondence_distance=0.015, init=icp_result,\n",
    "    #     estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    #     criteria=o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=1e-06, relative_rmse=1e-06, max_iteration=100))\n",
    "    # print(\"ICP: Fitness {:.2f} \\t MSE {:.2e}\".format(reg_p2p.fitness, reg_p2p.inlier_rmse))\n",
    "    # icp_result = reg_p2p.transformation\n",
    "    # t_local = time.time()\n",
    "    # print(\"ICP: Global {:.2f} sec. \\t Local {:.2e} sec.\".format(t_global - t_start, t_local - t_global))\n",
    "\n",
    "    if visualize:\n",
    "        draw_registration_result(source, target, icp_result)\n",
    "    \n",
    "    if reg_p2p.fitness < 0.8:\n",
    "        print(\"*\"*50)\n",
    "        print(\"*** WARNING: ICP fitness too low! ***\")\n",
    "        print(\"*\"*50)\n",
    "    \n",
    "    # source_new = copy.deepcopy(source).transform(icp_result)\n",
    "    # obb_new = source_new.get_oriented_bounding_box()\n",
    "    # obb_new.color = (0, 0, 1)\n",
    "    # o3d.visualization.draw_geometries([source, source_new, target, obb, obb_target, obb_new])\n",
    "    \n",
    "    if output_fitness:\n",
    "        return icp_result, reg_p2p.fitness\n",
    "\n",
    "    return icp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record an object pcd\n",
    "pcd = obs_env.get_pcd(return_numpy=False)\n",
    "pcd, bg_mask = bg.process_pcd(\n",
    "                    pcd,\n",
    "                    replace_bg=False,\n",
    "                    debug=False)\n",
    "obj_pcd = pcd.select_by_index(bg_mask, invert=True)\n",
    "\n",
    "# icp to the full pcd\n",
    "if full_pcd is None:\n",
    "    full_pcd = obj_pcd\n",
    "else:\n",
    "    transform = run_object_icp(obj_pcd, full_pcd, visualize=True)\n",
    "    transformed_obj_pcd = obj_pcd.transform(transform)\n",
    "\n",
    "    full_pcd_ = copy.deepcopy(full_pcd)\n",
    "    full_pcd_ += transformed_obj_pcd\n",
    "    full_pcd_ = full_pcd_.voxel_down_sample(voxel_size=0.005)\n",
    "    \n",
    "    o3d.visualization.draw_geometries([full_pcd_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "_, idx = full_pcd_.remove_statistical_outlier(nb_neighbors=10, std_ratio=0.03)\n",
    "display_inlier_outlier(full_pcd_, idx)\n",
    "o3d.visualization.draw_geometries([full_pcd_.select_by_index(idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pcd_ = full_pcd_.select_by_index(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pcd = full_pcd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pcd_dir = 'full_pcds'\n",
    "os.makedirs(full_pcd_dir, exist_ok=True)\n",
    "filepath = os.path.join(full_pcd_dir, f\"{obj_name}.pcd\")\n",
    "o3d.io.write_point_cloud(filepath, full_pcd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacman-real",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
